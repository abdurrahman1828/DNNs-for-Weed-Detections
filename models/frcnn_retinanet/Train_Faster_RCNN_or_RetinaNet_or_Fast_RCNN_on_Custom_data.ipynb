{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc8MmgZugZWR"
   },
   "source": [
    "# How to Train Detectron2 on Custom Objects\n",
    "\n",
    "This tutorial implements the new [Detectron2 Library](https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/) by facebook. This notebook shows training on **your own custom objects** for object detection.\n",
    "\n",
    "It is worth noting that the Detectron2 library goes far beyond object detection, supporting semantic segmentation, keypoint detection, mask, and densepose.\n",
    "\n",
    "\n",
    "### Accompanying Blog Post\n",
    "\n",
    "We recommend that you follow along in this notebook while reading the blog post on [how to train Detectron2](https://blog.roboflow.ai/how-to-train-detectron2/), concurrently.\n",
    "\n",
    "### Steps Covered in this Tutorial\n",
    "\n",
    "To train our detector we take the following steps:\n",
    "\n",
    "* Install Detectron2 dependencies\n",
    "* Download custom Detectron2 object detection data\n",
    "* Visualize Detectron2 training data\n",
    "* Write our Detectron2 Training configuration\n",
    "* Run Detectron2 training\n",
    "* Evaluate Detectron2 performance\n",
    "* Run Detectron2 inference on test images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nk0Kj1MO0q4L"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd6NebZ5hP0A"
   },
   "source": [
    "# Install Detectron2 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXisIbT1Zqou"
   },
   "outputs": [],
   "source": [
    "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
    "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "# opencv is pre-installed on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wW8A0IHVZ_MR"
   },
   "outputs": [],
   "source": [
    "# install detectron2:\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rCUZZnbhcyl"
   },
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd0NJiPJhiu7"
   },
   "source": [
    "# Import and Register Custom Detectron2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Mi9gsZzhokl"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/yolo_data/train/images/annotations.coco.json\", \"/content/drive/MyDrive/yolo_data/train/images\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/yolo_data/frcnn/valid/_annotations.coco.json\", \"/content/drive/MyDrive/yolo_data/frcnn/valid\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"/content/drive/MyDrive/yolo_data/frcnn/test/_annotations.coco.json\", \"/content/drive/MyDrive/yolo_data/frcnn/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdTAusKE9zUQ"
   },
   "outputs": [],
   "source": [
    "#visualize training data\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okQbhIYIh_CL"
   },
   "source": [
    "# Train Custom Detectron2 Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4UESNQ4tyVm"
   },
   "outputs": [],
   "source": [
    "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"/content/drive/MyDrive/yolo_data/frcnn/coco_eval_retina\", exist_ok=True)\n",
    "        output_folder = \"/content/drive/MyDrive/yolo_data/frcnn/coco_eval_retina\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPc8yVBVh52F"
   },
   "outputs": [],
   "source": [
    "#from .detectron2.tools.train_net import Trainer\n",
    "#from detectron2.engine import DefaultTrainer\n",
    "# select from modelzoo here: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md#coco-object-detection-baselines\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "#from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16 #decrese if GPU memory doesn't support\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 3\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 #your number of classes + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oca9rEQKif1h"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBUdNVhn1rHh"
   },
   "outputs": [],
   "source": [
    "#test evaluation\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3BX34iXw1gU"
   },
   "source": [
    "# Inference with Detectron2 Saved Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb65zpj87Bka"
   },
   "outputs": [],
   "source": [
    "%ls ./output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVBjf0DE7HEW"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiJ0Ylc_XAUa"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for imageName in glob.glob('/content/drive/MyDrive/yolo_data/frcnn/test/*jpg'):\n",
    "  print(imageName)\n",
    "  name = imageName.split(\"/\")[-1]\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=test_metadata, \n",
    "                scale=0.8\n",
    "                 )\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  #plt.savefig(out.get_image()[:, :, ::-1], dpi='figure', bbox_inches='tight', pad_inches=0.0 )\n",
    "  cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "  path = f\"/content/drive/MyDrive/R50_C4/{name}\"\n",
    "  #cv2.imwrite(f\"/content/drive/MyDrive/R50_C4/{name}\", out)\n",
    "  plt.savefig(path, dpi='figure', bbox_inches='tight', pad_inches=0.0)\n",
    "  #plt.show()\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Custom-Detectron2(abdur).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
